---
title: "Activity 9 - Bootstrapping"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(tidyverse)
library(tidymodels)
```

```{r}
# Set a random seed value so we can obtain the same "random" results
set.seed(2023)

# Create a data frame/tibble named sim_dat
sim_dat <- tibble(
# Explain what next line is doing
# This line generates 20 random numbers uniformly distributed between -5 and 5 and assigns them to the column   x1 in the data frame sim_dat.  
  x1 = runif(20, -5, 5),

# Explain what next line is doing
# This line generates 20 random numbers uniformly distributed between 0 and 100 and assigns them to the column   x2 in the data frame sim_dat.
  x2 = runif(20, 0, 100),

# Explain what next line is doing
# This line generates 20 random binary numbers (0 or 1) from a binomial distribution with a probability of 0.5  and assigns them to the column x3 in the data frame sim_dat.
  x3 = rbinom(20, 1, 0.5)
  )

b0 <- 2
b1 <- 0.25
b2 <- -0.5
b3 <- 1
sigma <- 1.5

errors <- rnorm(20, 0, sigma)

sim_dat <- sim_dat %>% 
  mutate(
    y = b0 + b1*x1 + b2*x2 + b3*x3 + errors,
    x3 = case_when(
      x3 == 0 ~ "No",
      TRUE ~ "Yes"
      )
    )
```

1) Go back through the previous code and explain what each line is doing by providing a comment. You are provided with an example in the first line and places for the rest of that code “sentence”. Do this for all the previous code chunk.

2) What is the true (population-level) model? Note that we are adding noise/variability, but based on the above code you can see what the “baseline” model is.

**The true (population-level) model, based on the coefficients defined in the code and excluding the noise/variability added by the errors, is:
y=2+0.25⋅x1−0.5⋅x2+1⋅x3**

3) Create graphical visualizations for the relationship between all variable pairs (i.e., y and each x and also each x pair). Provide a brief summary of what you see/notice. That is, how do these relationships compare with your comments from (1) and model in (2)? Especially for the relationship between y and each x. Hint: Do you remember what function/package makes this very easy to produce?

```{r}
# Load necessary packages
library(tibble)
library(dplyr)
library(ggplot2)
library(GGally)

# Set a random seed for reproducibility
set.seed(2023)

# Create the data frame/tibble
sim_dat <- tibble(
  x1 = runif(20, -5, 5),
  x2 = runif(20, 0, 100),
  x3 = rbinom(20, 1, 0.5)
)

b0 <- 2
b1 <- 0.25
b2 <- -0.5
b3 <- 1
sigma <- 1.5

errors <- rnorm(20, 0, sigma)

sim_dat <- sim_dat %>% 
  mutate(
    y = b0 + b1*x1 + b2*x2 + b3*x3 + errors,
    x3 = case_when(
      x3 == 0 ~ "No",
      TRUE ~ "Yes"
    )
  )

# Create pair plot
ggpairs(sim_dat)
```
## Task 4: Traditional MLR model
First we will fit an estimated model to our simulated data. Recall that we have done some similar work in past activities, but for ease of searching I will tell you what to do.

```{r}
mlr_fit <- linear_reg() %>%
  set_mode("regression") %>% 
  set_engine("lm") %>% 
  fit(y ~ x1 + x2 + x3, data = sim_dat)

# Also include the confidence intervals for our estimated slope parameters
tidy(mlr_fit, conf.int = TRUE)
```

4) Looking at your population-level model from (2), how accurate are your results? Explain how you made this decision. That is, what did you use from your output and how did you use that information to decide?

# Task 5: Bootstrapping

```{r}
# Set a random seed value so we can obtain the same "random" results
set.seed(631)

# Generate the 2000 bootstrap samples
boot_samps <- sim_dat %>% 
  bootstraps(times = 2000)

boot_samps
```
```{r}
# Create a function that fits a fixed MLR model to one split dataset
fit_mlr_boots <- function(split) {
  lm(y ~ x1 + x2 + x3, data = analysis(split))
}

# Fit the model to each split and store the information
# Also, obtain the tidy model information
boot_models <- boot_samps %>% 
  mutate(
    model = map(splits, fit_mlr_boots),
    coef_info = map(model, tidy)
    )

boots_coefs <- boot_models %>% 
  unnest(coef_info)

boots_coefs
```

```{r}
boot_int <- int_pctl(boot_models, statistics = coef_info, alpha = 0.05)
boot_int
```
```{r}
ggplot(boots_coefs, aes(x = estimate)) +
  geom_histogram(bins = 30) +
  facet_wrap( ~ term, scales = "free") +
  geom_vline(data = boot_int, aes(xintercept = .lower), col = "blue") +
  geom_vline(data = boot_int, aes(xintercept = .upper), col = "blue")
```
Looking at your population-level model from (2), how accurate are your results? Explain how you made this decision. That is, what did you use from your output and how did you use that information to decide?
